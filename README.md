# Hi there. I'm Micha≈Ç. üëã

I'm a Lead Data Scientist, Deep Learning Engineer and NLP enthusiast.

As a Lead Data Scientist, I apply my expertise in deep learning, natural language processing (NLP) and large language models (LLMs) to build and deploy state-of-the-art solutions. I have over 10 years of experience in developing and delivering machine learning and deep learning products that use structured and unstructured data at petabyte-scale. I am a published author in Nature and Springer journals, a multiple patents owner, and a conference speaker.

I am passionate about working with the latest advancements in NLP and LLMs, such as transformers networks, pre-trained models like Llama 2 or Mistral, fine-tuning techniques, RAG and more. I use PyTorch, TensorFlow, HuggingFace Transformers, PEFT, and TRL as my models development toolkit, and GCP Vertex AI and BigQuery as my cloud platforms.

I enjoy conducting end-to-end research projects, solving open-ended problems with a scientific approach, and communicating the results. I am also a product-oriented technical problem solver, keeping the business value perspective always in mind. I am experienced in project management and capable of handling multiple projects, priorities, or products simultaneously. I am a technical leader who helps others to deliver and learn, always a team player who cares for others, and a believer that only good teams can do great things.

## üöÄ Personal Projects 

- [Mistral-7B-Instruct-v0.2-Samsum-DialSum-SFTT](https://github.com/msznajder/mistral-7b-samsum-dialogue-summary-finetune) - Mistral 7B model parameter efficient fine-tuning for dialogue summarization with LoRA
- [ChatGPT and LangChain RAG](https://github.com/msznajder/llm_experiments/blob/main/01_rag_chatgpt_langchain_text_docs_chat.ipynb) - RAG-based text documents Q&A chat with LangChain and ChatGPT

## ‚ö° Skills And Technologies 

**ü§ñ Machine learning and deep learning**
* Models research, development and production deployment
* Models architectures, data preprocessing, feature engineering, hyperparameters tuning, loss functions and performance metrics

**‚úçÔ∏è Natural Language Processing (NLP) and Large Language Models (LLMs)**
* Architectures: RNN, LSTM, seq2seq, Transformers, etc.
* Pre-trained models: Llama 2, Mistral, GPT, BERT, T5, etc.
* Techniques: fine-tuning, PEFT (LoRA, QLoRA, Prompt Tuning), RAG, prompt engineering
* Tasks: sequence and token classification, translation, summarization, question answering, language modeling, dialogue, etc.

**üèóÔ∏è Models development toolkit**
* Python, NumPy, pandas, matplotlib and scikit-learn
* PyTorch, TensorFlow
* HuggingFace Transformers, PEFT, TRL, LangChain

**‚òÅÔ∏è Cloud models development and data acquisition**
* GCP Vertex AI models development and production deployment
* GCP BigQuery and SQL used with petabyte-scale data sets
* MLOps models deployment technologies and pipelines

**üß† Problem solving and research**
* Problem-solving with a creative, innovative and logical approach 
* Conduct scientific research individually and collectively
* Written and verbal communication and reporting skills, with the ability to explain complex technical concepts to non-experts

**üìí Team and project management**
* Technical leadership of ML and DL projects
* Project management and organizational skills for handling multiple projects
* Team player with natural team-building skills





<!--
**msznajder/msznajder** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
